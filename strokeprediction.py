# -*- coding: utf-8 -*-
"""StrokePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PQG7cfCY-y6OqHCFuDHUtL-SuChu0bHf
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split  as tts
import seaborn as sns

"""Importing the Dataset"""

# data = pd.read_csv('/content/drive/MyDrive/healthcare.csv')

data = pd.read_csv("/content/healthcare-dataset-stroke-data.csv")

data

data.info()

data.stroke.value_counts()

data.isna().sum()

data = data.dropna()
data = data.drop(columns = 'id')

"""##Data Analysis"""

for col in data.columns:
    plt.title(col)
    sns.histplot(x = col , data = data , hue = 'stroke' )
    plt.show()

sns.barplot(x = 'gender',y = 'age',hue = 'stroke',data = data)

"""##Encoding of Categorical Features

We performed encoding of Categorical columns using label encoder
"""

from sklearn.preprocessing import LabelEncoder

col = ['gender','ever_married','work_type','Residence_type','smoking_status']
for i in col:
  le = LabelEncoder()
  le.fit(data[i])
  data[i] = le.fit_transform(data[i])

y = data.iloc[:,-1]

data

"""##Scaling of Continuous Features

Then we performed Standardization of Continuous columns using StandardScaler
"""

dcopy = data.copy(deep = True)
dcopy

from sklearn.preprocessing import StandardScaler
scaled_features = data.copy()
 
cols = ['age', 'avg_glucose_level','bmi']
features = dcopy[cols]
scaler = StandardScaler().fit(features.values)
features = scaler.transform(features.values)
 
dcopy[cols] = features
dcopy

data = dcopy
data

"""#Dropping unnecessary columns

"""

plt.figure(figsize = (10,7))
sns.heatmap(data.corr(), annot = True, cmap = "RdYlGn")
plt.show()

"""Dropping the columns -> bmi , Hypertension , Heart Disease and ever married . We dropped bmi because it had a lot of outlier values as evident from its graph . There was a lot of imbalance in the data in columns of Hypertension and Heart disease .We dropped ever_married because it was highly correlated to the Age column"""

data = data.drop(columns = ['bmi' , 'hypertension' , 'heart_disease' , 'ever_married'])

data.isna().sum()

"""Splitting into training and testing data"""

X_train, X_test, Y_train, Y_test = tts(data.iloc[:, :-1], data.iloc[:,-1], test_size = 0.3, shuffle = True)

"""#Importing the Models

Evaluating the performance of some well known classifier models
"""

from sklearn.ensemble import RandomForestClassifier as RFC
from sklearn.ensemble import AdaBoostClassifier as ABC
from sklearn.svm import SVC 
from sklearn.tree import DecisionTreeClassifier
import xgboost as xgb
import lightgbm as lgb
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score as acc
from sklearn.metrics import f1_score as f1

models = []
models.append(RFC())
models.append(ABC())
models.append(SVC(kernel = 'linear' , C = 0.1))
models.append(DecisionTreeClassifier())
models.append(xgb.XGBClassifier())
models.append(lgb.LGBMClassifier())+

models.append(KNeighborsClassifier())

!pip install tabulate
from tabulate import tabulate

table = [["Model" , "Training accuracy" ,"Testing accuracy" , "Testing F1 score" ]]
for i in range(len(models)):
  clf = models[i]
  clf.fit(X_train, Y_train)
  ind_reg = [clf , acc(Y_train , clf.predict(X_train)) ,  acc(Y_test , clf.predict(X_test))  , f1(Y_test , clf.predict(X_test))]
  # print(clf,' : ', acc(Y_test, clf.predict(X_test)),',' , f1(Y_test, clf.predict(X_test)))
  table.append(ind_reg)
print(tabulate(table ,headers = 'firstrow' ,  tablefmt='fancy_grid'))

"""We can see that precision and F1 score  are very small in all places because the number of datapoints for 1s are very less as compared to 0s. So for equally training 1s class labels, we used oversampling on the train data  using RandomOverSampler . This increases the number of datapoints of 1s class equal to the number of 0s class. This will help train 1s class equally

#Oversampling on training data
"""

! pip install -U imbalanced-learn

from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(random_state=0)
X, Y = ros.fit_resample(X_train, Y_train)

Y.value_counts()

table = [["Model" , "Training accuracy" ,"Testing accuracy" , "Testing F1 score" ]]
for i in range(len(models)):
  clf = models[i]
  clf.fit(X, Y)
  ind_reg = [clf , acc(Y , clf.predict(X)) ,  acc(Y_test , clf.predict(X_test))  , f1(Y_test , clf.predict(X_test))]
  # print(clf,' : ', acc(Y_test, clf.predict(X_test)),',' , f1(Y_test, clf.predict(X_test)))
  table.append(ind_reg)
print(tabulate(table ,headers = 'firstrow' ,  tablefmt='fancy_grid'))

"""The F1 scores have increased a bit, but are still less so we tried applying oversampling on whole data, rather than training data

#Oversampling on whole data

We tried performing Oversampling on the whole data , but it is wrong as we will be testing the model on manipulated data so it may perform poorly on unseen data.
"""

ros = RandomOverSampler(random_state=0)
Xw, Yw = ros.fit_resample(data.iloc[:, :-1], data.iloc[:,-1])

Yw.value_counts()

Xw_train, Xw_test, Yw_train, Yw_test = tts(Xw, Yw, test_size = 0.3, shuffle = True)

table = [["Model" , "Training accuracy" ,"Testing accuracy" , "Testing F1 score" ]]
for i in range(len(models)):
  clf = models[i]
  clf.fit(Xw_train, Yw_train)
  ind_reg = [clf , acc(Yw_train , clf.predict(Xw_train)) ,  acc(Yw_test , clf.predict(Xw_test))  , f1(Yw_test , clf.predict(Xw_test))]
  # print(clf,' : ', acc(Y_test, clf.predict(X_test)),',' , f1(Y_test, clf.predict(X_test)))
  table.append(ind_reg)
print(tabulate(table ,headers = 'firstrow' ,  tablefmt='fancy_grid'))

"""LGBM Classifier has performed considerably well in all the three cases . So We decided to perform its hyperparameter tuning to furthur enhance its performance

#Hyperparameter Tuning
"""

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score as auc
from sklearn.metrics import roc_curve as roc

mdl_rf = lgb.LGBMClassifier()
params_li = { 'n_estimators': [200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth' : list(range(30,50)) }
rf_gs = GridSearchCV(estimator=mdl_rf, param_grid = params_li , cv= 3 )

rf_gs.fit(Xw_train, Yw_train)

rf_gs.best_params_

mdl_best = rf_gs.best_estimator_

table = [["Data" , "Training accuracy" ,"Testing accuracy" , "Testing F1 score" , "Testing AUC" ]]
mdl_best.fit(X_train , Y_train)
y_pred = mdl_best.predict(X_test)
table.append(["Unsampled Data" , acc(Y_train ,mdl_best.predict(X_train)) , acc(Y_test , y_pred) ,f1(Y_test , y_pred) , auc(Y_test , mdl_best.predict_proba(X_test)[:,1])] )
y_predprob_unsampled = mdl_best.predict_proba(X_test)[:,1]

mdl_best.fit(X , Y)
y_pred = mdl_best.predict(X_test)
table.append(["Oversampled (training only)" , acc(Y ,mdl_best.predict(X)) , acc(Y_test , y_pred) ,f1(Y_test , y_pred) , auc(Y_test , mdl_best.predict_proba(X_test)[:,1])] )
y_predprob_sampled_tr = mdl_best.predict_proba(X_test)[:,1]

mdl_best.fit(Xw_train , Yw_train)
y_pred = mdl_best.predict(Xw_test)
table.append(["Oversampled (whole data)" , acc(Yw_train ,mdl_best.predict(Xw_train)) , acc(Yw_test , y_pred) ,f1(Yw_test , y_pred) , auc(Yw_test , mdl_best.predict_proba(Xw_test)[:,1])] )
y_predprob_sampled_whole = mdl_best.predict_proba(Xw_test)[:,1]

print(tabulate(table ,headers = 'firstrow' ,  tablefmt='fancy_grid'))

fpr , tpr , _ = roc(Y_test , y_predprob_unsampled)
plt.plot(fpr,tpr , label = "AUC : " +  str(auc(Y_test , y_predprob_unsampled)) , color = 'r')
plt.title("ROC for LGBM Classifier with Unsampled data")
plt.xlabel("False Positive Rate")
plt.legend()
plt.ylabel("True Positive Rate")
plt.show()

fpr , tpr , _ = roc(Y_test , y_predprob_sampled_tr)
plt.plot(fpr,tpr , label = "AUC : " +  str(auc(Y_test , y_predprob_sampled_tr)) , color = 'b')
plt.title("ROC for LGBM Classifier with Sampled data(Training Only)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

fpr , tpr , _ = roc(Yw_test , y_predprob_sampled_whole)
plt.plot(fpr,tpr , label = "AUC : " +  str(auc(Yw_test , y_predprob_sampled_whole)) , color = 'g')
plt.title("ROC for LGBM Classifier with Sampled data|(whole)")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

"""#NN"""

import torch
import torch.nn as nn
from torch.autograd import Variable
from sklearn.utils import shuffle
from torchsummary import summary

def get_accuracy(logit, target, batch_size):
    
    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()
    accuracy = 100.0 * corrects/batch_size
    return accuracy.item()

X_train=X_train.values
Y_train=Y_train.values

batch_size = 30 
num_epochs = 1000
learning_rate = 0.01
size_hidden_1 = 200 
size_hidden_2 = 200 
num_classes = 2

batch_no = len(X_train) // batch_size

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
class Net(torch.nn.Module):
    def __init__(self, num_inputs, size_hidden_1, size_hidden_2, n_output):
        super(Net, self).__init__()
        self.hidden_layer_1 = torch.nn.Linear(num_inputs, size_hidden_1)   # hidden layer
        self.activation_1 = torch.nn.Tanh() # activation layer
        self.hidden_layer_2 = torch.nn.Linear(size_hidden_1, size_hidden_2)   # hidden layer
        self.activation_2 = torch.nn.Tanh() # activation layer
        
        self.output_layer = torch.nn.Linear(size_hidden_2, n_output)   # output layer
        self.output_act = torch.nn.Sigmoid()

    def forward(self, x):
        x = self.activation_1(self.hidden_layer_1(x))      # activation function for hidden layer
        x = self.activation_2(self.hidden_layer_2(x))      # activation function for hidden layer
        x = self.output_act(self.output_layer(x))                    # output
        return x

net = Net(6, size_hidden_1, size_hidden_2, num_classes)
summary(net, (1,6))

optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)
loss_func = torch.nn.CrossEntropyLoss()

# Commented out IPython magic to ensure Python compatibility.
for epoch in range(num_epochs):
    #Shuffle just mixes up the dataset between epocs
    X_train, Y_train = shuffle(X_train, Y_train)

    train_acc = 0.0
    running_loss = 0.0

    # Mini batch learning
    for i in range(batch_no):
        start = i * batch_size
        end = start + batch_size
        inputs = Variable(torch.FloatTensor(X_train[start:end]))
        labels = Variable(torch.LongTensor(Y_train[start:end]))
        
        # zero the parameter gradients
        optimizer.zero_grad()
               
        outputs = net(inputs)
        
        loss = loss_func(outputs, labels)
        
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        val = get_accuracy(outputs, labels, batch_size)
        train_acc += val
      
    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \
#           %(epoch+1, running_loss / (i+1), train_acc/(i+1)))  
    running_loss = 0.0

"""The training Accuracy for neural network is not that good compared to other models so we decided to drop it

#Pipeline

Implementing a pipeline with LabelEncoder and StandardScaler for preprocessing and LGBM Classifier as the classification model
"""

from sklearn.pipeline import Pipeline
from sklearn import set_config
from sklearn.base import BaseEstimator
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import make_pipeline

from sklearn.base import TransformerMixin
class preprocess(BaseEstimator , TransformerMixin):
  def __init__(self):
    print("init() function called")

  def fit(self , X , y = None):
    print("fit() function called")
    return self
  def transform(self , X , y = None):
    X = X.drop(columns = ['bmi' , 'hypertension' , 'heart_disease' , 'ever_married' , 'id'])
    continuous_columns = ['age', 'avg_glucose_level']
    categorical_columns = ['gender','work_type','Residence_type','smoking_status']
    scaler = StandardScaler()
    le = LabelEncoder()
    X[continuous_columns] = scaler.fit_transform(X[continuous_columns])
    for col in categorical_columns:
      X[col] = le.fit_transform(X[col])
    
    return X

pl = Pipeline([ ('preprocess' , preprocess()), ('classifier', rf_gs.best_estimator_) ])
new_data = pd.read_csv("/content/healthcare-dataset-stroke-data.csv")
new_data = new_data.dropna()
x_train , x_test, y_train , y_test = tts(new_data.drop(columns = 'stroke') , new_data.stroke , test_size = 0.3 , shuffle = True)
# print(x_train)
pl.fit(x_train, y_train)
y_pred = pl.predict(x_test)

a , b = np.unique(y_pred , return_counts = True)
print("Number of 0s and 1s in the predicted data is : " , b)
a , b = np.unique(y_test , return_counts = True)
print("Number of 0s and 1s in the actual testing data is : " ,b)
print("Accuracy : " , acc(y_test , y_pred ))
print("F1 Score : " , f1( y_test , y_pred))

set_config(display="diagram")
pl